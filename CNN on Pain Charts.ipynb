{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain Charts classification with CNN\n",
    "\n",
    "Idea: Creation of a simple a classifier for the groups found in Boudreau et al 2018\n",
    "\n",
    "- Data from Patellofemoral Pain Patients\n",
    "- Groups defined by a unsupervised cluster classfication (K-means)\n",
    "\n",
    "Method: Application of a CNN with a simple architecture and build up from here\n",
    "     \n",
    "Reference: Boudreau, S.A., Royo, A.C., Matthews, M. et al. Distinct patterns of variation in the distribution of knee pain. Sci Rep 8, 16522 (2018). www.nature.com/articles/s41598-018-34950-2</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import of the the main \n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import InputLayer,Input, Add, Dense, Activation,ZeroPadding2D, ZeroPadding1D, BatchNormalization, Flatten, Conv1D, Conv2D, AveragePooling2D, AveragePooling1D,MaxPooling2D, MaxPooling1D, GlobalMaxPooling1D,GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils, to_categorical   \n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import lmdb\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files imported is 299\n"
     ]
    }
   ],
   "source": [
    "# Let's import the file names from our dataset\n",
    "fileNames = glob.glob(r'C:\\Users\\Albert\\Documents\\GitHub\\PC data\\*.png')\n",
    "print('Number of files imported is',len(fileNames))\n",
    "kernel = np.array([[0,1,0],[1,1,1],[0,1,0]],np.uint8)\n",
    "binIms = []   \n",
    "PainChartList = []\n",
    "\n",
    "RawDataList = []\n",
    "\n",
    "for fileName in fileNames:\n",
    "    im = cv2.imread(fileName)\n",
    "    RawDataList.append(im)\n",
    "    binIm = np.zeros(np.shape(im)[0:2])\n",
    "    #Creating a mask from the pain Image, this will be the binarized version of the image\n",
    "    binIm[(im[:,:,2]>150) & (im[:,:,0]==0)] = 1\n",
    "    #Open the pain region so small empty spaces within the pain region are filled\n",
    "    binIm = cv2.morphologyEx(binIm, cv2.MORPH_CLOSE, kernel)\n",
    "    #Saving images in a List \n",
    "    PainChartList.append(binIm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.loadtxt('C:/Users/Albert/Documents/GitHub/classesK4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayPain = np.asarray(PainChartList)\n",
    "arrayPainCropped = arrayPain[:,int(arrayPain.shape[1]/2):int(arrayPain.shape[1]),:]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(arrayPainCropped, y, test_size=0.3)\n",
    "X_trainR = np.expand_dims(X_train,3)\n",
    "X_testR = np.expand_dims(X_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 209\n",
      "number of test examples = 90\n",
      "X_trainR shape: (209, 568, 447, 1)\n",
      "Y_train shape: (209, 4)\n",
      "X_testR shape: (90, 568, 447, 1)\n",
      "Y_test shape: (90, 4)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_trainR.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_testR.shape[0]))\n",
    "print (\"X_trainR shape: \" + str(X_trainR.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_testR shape: \" + str(X_testR.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PainNet(input_shape = (568, 447, 1), classes = 4):\n",
    "    \"\"\"\n",
    "    Implementation of PainNet the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL \n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset (?,568, 447, 1)\n",
    "    classes -- integer, number of classes (?,4)\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "   \n",
    "    # Stage 1\n",
    "    X = Conv2D(32, (15,15), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X) #(228, 168, 64)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X) #114, 84, 64\n",
    "    \n",
    "    # Stage 2\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv2', kernel_initializer = glorot_uniform(seed=0))(X) #(50,35,128)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "     # Stage 3\n",
    "    X = Conv2D(128, (2, 2), strides = (2, 2), name = 'conv3', kernel_initializer = glorot_uniform(seed=0))(X) #(50,35,128)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "   ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='PainNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PainNet(classes = 4)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PainNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 568, 447, 1)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 574, 453, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 280, 220, 32)      7232      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 280, 220, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 280, 220, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 139, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 67, 52, 64)        100416    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 67, 52, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 67, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 33, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 12, 128)       32896     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 16, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 4)                 24580     \n",
      "=================================================================\n",
      "Total params: 166,020\n",
      "Trainable params: 165,572\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 209\n",
      "number of test examples = 90\n",
      "X_trainR shape: (209, 568, 447, 1)\n",
      "Y_train shape: (209, 4)\n",
      "X_testR shape: (90, 568, 447, 1)\n",
      "Y_test shape: (90, 4)\n"
     ]
    }
   ],
   "source": [
    "Y_train = to_categorical(Y_train.T, num_classes=4)\n",
    "Y_test = to_categorical(Y_test.T, num_classes=4)\n",
    "print (\"number of training examples = \" + str(X_trainR.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_testR.shape[0]))\n",
    "print (\"X_trainR shape: \" + str(X_trainR.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_testR shape: \" + str(X_testR.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "209/209 [==============================] - 74s 356ms/step - loss: 2.0793 - accuracy: 0.4450\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 65s 311ms/step - loss: 1.3521 - accuracy: 0.5311\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 64s 306ms/step - loss: 1.2661 - accuracy: 0.5502\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 63s 302ms/step - loss: 1.2671 - accuracy: 0.5311\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 78s 372ms/step - loss: 1.2218 - accuracy: 0.5502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22c3e39a048>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trainR,Y_train,epochs = 5, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranfer learning from ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50,MobileNet,VGG16 \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading ResNet50 excluding the last layers\n",
    "base_model = VGG16 (weights = 'imagenet',include_top = False) #,input_shape=(568, 447, 3)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(568, 447, 1))\n",
    "dense_filter = Conv2D(3, 3, padding='same')(input_layer)\n",
    "X = base_model(dense_filter)\n",
    "X =  Flatten()(X)\n",
    "outputs = Dense(4,activation='softmax')(X)\n",
    "new_model = Model(input_layer,outputs)\n",
    "for layer in new_model.layers[2:16]:\n",
    "    layer.trainable=False\n",
    "for layer in new_model.layers[16:]:\n",
    "    layer.trainable=True\n",
    "new_model.layers[1].trainable=True\n",
    "new_model.layers[-1].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_input = tf.keras.layers.Input(shape=(448, 448, 6))\n",
    "dense_filter = tf.keras.layers.Conv2D(3, 3, padding='same')(dense_input)\n",
    "X = orig_model(dense_filter)\n",
    "\n",
    "model = tf.keras.Model(dense_input, output)\n",
    "model.compile(...)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture of the new Model accomplished\n",
    "new_model=Model(inputs=base_model.input,outputs=preds)\n",
    "#set the first 30 layers of the network to be non-trainable\n",
    "for layer in new_model.layers[1:30]:\n",
    "    layer.trainable=False\n",
    "for layer in new_model.layers[30:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arrayPain2 = np.asarray(PainChartList)\n",
    "arrayPainCropped2 = np.expand_dims(arrayPain2[:,int(arrayPain2.shape[1]/2):int(arrayPain2.shape[1]),:],axis=3)\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(arrayPainCropped2, y, test_size=0.3)\n",
    "Y_train2 = to_categorical(Y_train2.T, num_classes=4)\n",
    "Y_test2 = to_categorical(Y_test2.T, num_classes=4)\n",
    "print (\"number of training examples = \" + str(X_train2.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test2.shape[0]))\n",
    "print (\"X_train2 shape: \" + str(X_train2.shape))\n",
    "print (\"Y_train2 shape: \" + str(Y_train2.shape))\n",
    "print (\"X_test2 shape: \" + str(X_test2.shape))\n",
    "print (\"Y_test2 shape: \" + str(Y_test2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.fit(X_train2,Y_train2, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
